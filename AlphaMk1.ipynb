{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory where we will\n",
    "# store our smaller dataset\n",
    "base_dir = '/home/alejandro/Downloads/ProyectoAlpha/Data/'\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "validation_dir = os.path.join(base_dir, 'Validate')\n",
    "\n",
    "# Directory with our training Regular Coke pictures\n",
    "train_Coke_dir = os.path.join(train_dir, 'CocaCoke')\n",
    "\n",
    "# Directory with our training Diet Coke pictures\n",
    "train_Diet_dir = os.path.join(train_dir, 'DietCoka')\n",
    "\n",
    "# Directory with our training Apple Joya pictures\n",
    "train_Apple_dir = os.path.join(train_dir, 'JoyaManzana')\n",
    "\n",
    "# Directory with our training Fanta pictures\n",
    "train_Fanta_dir = os.path.join(train_dir, 'Fanta')\n",
    "\n",
    "# Directory with our training Pepsi Cola pictures\n",
    "train_Pepsi_dir = os.path.join(train_dir, 'Pepsi')\n",
    "\n",
    "# Directory with our validation Regular Coke pictures\n",
    "validation_Coke_dir = os.path.join(validation_dir, 'CocaCola')\n",
    "\n",
    "# Directory with our validation Diet Coke pictures\n",
    "validation_Diet_dir = os.path.join(validation_dir, 'DietCoke')\n",
    "\n",
    "# Directory with our validation Apple Joya pictures\n",
    "validation_Apple_dir = os.path.join(validation_dir, 'JoyaManzana')\n",
    "\n",
    "# Directory with our validation Fanta pictures\n",
    "validation_Fanta_dir = os.path.join(validation_dir, 'Fanta')\n",
    "\n",
    "# Directory with our validation Pepsi Cola pictures\n",
    "validation_Pepsi_dir = os.path.join(validation_dir, 'Pepsi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Coca, 2: Dieta, 3: Manzana, 4: Fanta, 5: Pepsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(224, 224),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CarCrashModelMk1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('AlphaModelMk1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image1 = load_img('Coca.jpg', target_size=(224,224))\n",
    "plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image2 = load_img('Diet.jpg', target_size=(224,224))\n",
    "plt.imshow(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image3 = load_img('Manzana.jpg', target_size=(224,224))\n",
    "plt.imshow(image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image4 = load_img('Fanta.jpg', target_size=(224,224))\n",
    "plt.imshow(image4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image5 = load_img('Pepsi.jpg', target_size=(224,224))\n",
    "plt.imshow(image5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1= img_to_array(image1)\n",
    "#image1 /=255\n",
    "image2= img_to_array(image2)\n",
    "#image1 /=255\n",
    "image3= img_to_array(image3)\n",
    "#image1 /=255\n",
    "image4= img_to_array(image4)\n",
    "#image1 /=255\n",
    "image5= img_to_array(image5)\n",
    "#image1 /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image1.reshape((1,image1.shape[0], image1.shape[1], image1.shape[2]))\n",
    "image2 = image2.reshape((1,image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "image3 = image3.reshape((1,image3.shape[0], image3.shape[1], image3.shape[2]))\n",
    "image4 = image4.reshape((1,image4.shape[0], image4.shape[1], image4.shape[2]))\n",
    "image5 = image5.reshape((1,image5.shape[0], image5.shape[1], image5.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability across all output classes\n",
    "pred1 = model.predict(image1)\n",
    "print(pred1)\n",
    "pred2 = model.predict(image2)\n",
    "print(pred2)\n",
    "pred3 = model.predict(image3)\n",
    "print(pred3)\n",
    "pred4 = model.predict(image4)\n",
    "print(pred4)\n",
    "pred5 = model.predict(image5)\n",
    "print(pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precisi√≥n del ~80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image1 = load_img('section1.jpg', target_size=(224,224))\n",
    "plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1= img_to_array(image1)\n",
    "#image1 /=255\n",
    "image1 = image1.reshape((1,image1.shape[0], image1.shape[1], image1.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability across all output classes\n",
    "pred1 = model.predict(image1)\n",
    "print(pred1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
